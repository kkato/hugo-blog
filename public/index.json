[{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りありますが、今回はGitHub Appを使います。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\n詳しくは公式ドキュメントを参照してください: https://docs.renovatebot.com/presets-config/#configrecommended\nカスタム設定 詳しくは公式ドキュメントを参照してください: https://docs.renovatebot.com/configuration-options/\nまとめ ","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りありますが、今回はGitHub Appを使います。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003e詳しくは公式ドキュメントを参照してください: \u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003ehttps://docs.renovatebot.com/presets-config/#configrecommended\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"カスタム設定\"\u003eカスタム設定\u003c/h2\u003e\n\u003cp\u003e詳しくは公式ドキュメントを参照してください: \u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003ehttps://docs.renovatebot.com/configuration-options/\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e","title":"Renovateの導入方法"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りありますが、今回は手軽に使いたいので、GitHub Appを使います。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら\nまたその他設定項目についてはこちら\nまとめ 現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りありますが、今回は手軽に使いたいので、GitHub Appを使います。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。今回は手軽に使いたいので、GitHub Appを使います。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら\nまたその他設定項目についてはこちら\nまとめ 現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。今回は手軽に使いたいので、GitHub Appを使います。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使います。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら\nまたその他設定項目についてはこちら\nまとめ 現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使います。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら\nまたその他設定項目についてはこちら\nまとめ 現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovateを使っていて、設定項目が多いがゆえにややとっつにくい印象がありました。しかし、導入自体はとてもシンプルで、すぐに利用を開始できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 想像よりも簡単にRenovateを導入できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e想像よりも簡単にRenovateを導入できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 想像よりも簡単にRenovateを導入できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e想像よりも簡単にRenovateを導入できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 想像よりも簡単にRenovateを導入できました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e想像よりも簡単にRenovateを導入できました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くて最初はややとっつきにくいという点でした。ドキュメントを読みながら一つ一つ理解していく必要があり、慣れるまでは少し苦労するかもしれません。\nしかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができ、慣れてくれば柔軟なルール設定でプロジェクトに最適な運用ができるのも魅力です。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くて最初はややとっつきにくいという点でした。ドキュメントを読みながら一つ一つ理解していく必要があり、慣れるまでは少し苦労するかもしれません。\u003c/p\u003e\n\u003cp\u003eしかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができ、慣れてくれば柔軟なルール設定でプロジェクトに最適な運用ができるのも魅力です。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くてややとっつきにくいという点でした。しかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができたので、もう少しドキュメントを読んで複雑な設定も試してみたいと思いました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くてややとっつきにくいという点でした。しかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができたので、もう少しドキュメントを読んで複雑な設定も試してみたいと思いました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くてややとっつきにくいという点でした。しかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができたので、もう少しドキュメントを読んで複雑な設定も試してみたいと思いました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くてややとっつきにくいという点でした。しかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができたので、もう少しドキュメントを読んで複雑な設定も試してみたいと思いました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"},{"content":"","permalink":"http://localhost:1313/posts/install-cloudnativepg/","summary":"","title":"Install Cloudnativepg"},{"content":"","permalink":"http://localhost:1313/posts/postgres-operators/","summary":"","title":"Postgres Operators"},{"content":"","permalink":"http://localhost:1313/posts/install-argocd/","summary":"","title":"ArgoCD Install"},{"content":"手動での依存パッケージのアップデートが大変だったので、Renovateを導入してみました。 その手順と設定について簡単にメモします。\nRenovateとは？ Renovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\nリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。 Node.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\n対応しているパッケージマネージャーの一覧はこちら\n導入手順 renovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\nhttps://github.com/apps/renovate から「Configure」を押す 全てのリポジトリを選択し、導入する 全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。 そのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\nrenovateの設定ファイルrenovate.jsonを作成し、リポジトリのrootにpushする 各リポジトリでConfigure RenovateというPull Requestが自動的に作成されます。\n自動生成されたrenovate.json\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:recommended\u0026#34; ] } $schema Renovateにおける$schemaは、renovate.jsonで使える設定項目やその値の種類・ルールを定義しています。 これにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\nextends extendsでは、Renovateがあらかじめ用意しているルールセットを指定することができます。 上記の例ではconfig:recommendedを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。 （以前はconfig:recommendedではなく、config:baseと呼ばれていたみたいです。）\nconfig:recommended の詳細についてはこちら またその他設定項目についてはこちら\nまとめ 現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くてややとっつきにくいという点でした。しかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができたので、もう少しドキュメントを読んで複雑な設定も試してみたいと思いました。\n","permalink":"http://localhost:1313/posts/install-renovate/","summary":"\u003cp\u003e手動での依存パッケージのアップデートが大変だったので、\u003ca href=\"https://docs.renovatebot.com/\"\u003eRenovate\u003c/a\u003eを導入してみました。\nその手順と設定について簡単にメモします。\u003c/p\u003e\n\u003ch2 id=\"renovateとは\"\u003eRenovateとは？\u003c/h2\u003e\n\u003cp\u003eRenovateは、依存関係の更新を自動化してくれるOSSのツールです。元々は個人開発から始まり、現在はイスラエルのセキュリティ企業 Mend社によって開発されています。\u003c/p\u003e\n\u003cp\u003eリポジトリ内の依存関係をスキャンし、新しいバージョンが利用可能な場合には自動でPull Request（PR）を作成してくれます。\nNode.jsのnpmやyarnはもちろん、Go modules、Docker、Terraformなど多くの言語やパッケージマネージャーに対応しているのも特徴です。\u003c/p\u003e\n\u003cp\u003e対応しているパッケージマネージャーの一覧は\u003ca href=\"https://docs.renovatebot.com/modules/manager/#supported-managers\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"導入手順\"\u003e導入手順\u003c/h2\u003e\n\u003cp\u003erenovateはセルフホストする方法とGitHub Appを使う方法の2通りあります。手軽に使いたいので、今回はGitHub Appを使って導入します。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/apps/renovate\"\u003ehttps://github.com/apps/renovate\u003c/a\u003e から「Configure」を押す\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure.png\"\u003e\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e全てのリポジトリを選択し、導入する\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e全てのリポジトリを選択したとしても、renovateの設定ファイルがあるリポジトリのみrenovateが有効になります。\nそのため、renovateの設定ファイルがないリポジトリではrenovateが無効化されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/repository-access.png\"\u003e\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003erenovateの設定ファイル\u003ccode\u003erenovate.json\u003c/code\u003eを作成し、リポジトリのrootにpushする\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e各リポジトリで\u003ccode\u003eConfigure Renovate\u003c/code\u003eというPull Requestが自動的に作成されます。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/install-renovate/configure-renovate.png\"\u003e\u003c/p\u003e\n\u003cp\u003e自動生成された\u003ccode\u003erenovate.json\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-json\" data-lang=\"json\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;$schema\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"nt\"\u003e\u0026#34;extends\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;config:recommended\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003ccode\u003e$schema\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eRenovateにおける\u003ccode\u003e$schema\u003c/code\u003eは、\u003ccode\u003erenovate.json\u003c/code\u003eで使える設定項目やその値の種類・ルールを定義しています。\nこれにより、どの設定が有効かをエディタが理解できたり、エディタによる補完などが有効になったりします。\u003c/p\u003e\n\u003ch3 id=\"extends\"\u003e\u003ccode\u003eextends\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eextends\u003c/code\u003eでは、Renovateがあらかじめ用意しているルールセットを指定することができます。\n上記の例では\u003ccode\u003econfig:recommended\u003c/code\u003eを指定しています。これには、どの言語やプロジェクトでも使える推奨設定が含まれています。\n（以前は\u003ccode\u003econfig:recommended\u003c/code\u003eではなく、\u003ccode\u003econfig:base\u003c/code\u003eと呼ばれていたみたいです。）\u003c/p\u003e\n\u003cp\u003econfig:recommended の詳細については\u003ca href=\"https://docs.renovatebot.com/presets-config/#configrecommended\"\u003eこちら\u003c/a\u003e \u003cbr\u003e\nまたその他設定項目については\u003ca href=\"https://docs.renovatebot.com/configuration-options/\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e現在業務でRenovate を使ってみて感じたのは、カスタマイズ性が非常に高い反面、設定項目が多くてややとっつきにくいという点でした。しかし、プライベートの時間を使って軽く触ってみたところ、導入自体は驚くほど簡単で、いい意味で期待を裏切られました。最小限の設定でもすぐに使い始めることができたので、もう少しドキュメントを読んで複雑な設定も試してみたいと思いました。\u003c/p\u003e","title":"Renovateの導入方法"},{"content":"PostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\nPostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\n% git clone git://git.postgresql.org/git/postgresql.git % cd postgresql % ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 % make -j 4 % make install configureコマンドには以下のオプションを指定しています。\nデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests インストール先のディレクトリを指定するオプション: \u0026ndash;prefix 参考: https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\nicu-uc, icu-i18nのパッケージが見つからない icu-uc, icu-i18nのパッケージが見つからないと言われました。\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0 (省略) checking for icu-uc icu-i18n... no configure: error: Package requirements (icu-uc icu-i18n) were not met: No package \u0026#39;icu-uc\u0026#39; found No package \u0026#39;icu-i18n\u0026#39; found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables ICU_CFLAGS and ICU_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details. PKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。 以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\n% brew info icu4c (省略) For pkg-config to find icu4c you may need to set: export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34; 言われた通りに設定しました。\necho \u0026#39;export PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/icu4c/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc TAPテストに必要なモジュールがインストールされていない TAPテストに必要なPerlのmoduleがインストールされていなかったみたいです。\nchecking for Perl modules required for TAP tests... Can\u0026#39;t locate IPC/Run.pm in @INC (you may need to install the IPC::Run module) (@INC contains: /Library/Perl/5.34/darwin-thread-multi-2level /Library/Perl/5.34 /Network/Library/Perl/5.34/darwin-thread-multi-2level /Network/Library/Perl/5.34 /Library/Perl/Updates/5.34.1 /System/Library/Perl/5.34/darwin-thread-multi-2level /System/Library/Perl/5.34 /System/Library/Perl/Extras/5.34/darwin-thread-multi-2level /System/Library/Perl/Extras/5.34) at ./config/check_modules.pl line 14. BEGIN failed--compilation aborted at ./config/check_modules.pl line 14. configure: error: Additional Perl modules are required to run TAP tests TAPテストに必要なPerlのmoduleをインストールしました。\n参考: https://www.postgresql.jp/document/16/html/regress-tap.html\nsudo cpan IPC::Run 参考 公式ドキュメント PostgreSQL開発コミュニティに参加しよう！ ","permalink":"http://localhost:1313/posts/postgresql16-build/","summary":"\u003cp\u003ePostgreSQL16をソースコードからビルドしてみたのですが、いくつかつまづいたポイントがあるので、それらにご紹介します。\u003c/p\u003e\n\u003cp\u003ePostgreSQL16をソースコードからビルドするためのコマンドは以下のとおりです。前提として M1 Mac (macOS 14.4.1) を使っています。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% git clone git://git.postgresql.org/git/postgresql.git\n% cd postgresql\n% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n% make -j 4\n% make install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003econfigureコマンドには以下のオプションを指定しています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eデバッグしやすくするためのオプション: \u0026ndash;enable-debug \u0026ndash;enable-cassert \u0026ndash;enable-tap-tests\u003c/li\u003e\n\u003cli\u003eインストール先のディレクトリを指定するオプション: \u0026ndash;prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考: \u003ca href=\"https://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\"\u003ehttps://www.postgresql.jp/document/16/html/install-make.html#CONFIGURE-OPTIONS\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"icu-uc-icu-i18nのパッケージが見つからない\"\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからない\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eicu-uc\u003c/code\u003e, \u003ccode\u003eicu-i18n\u003c/code\u003eのパッケージが見つからないと言われました。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e% ./configure --enable-debug --enable-cassert --enable-tap-tests --prefix=$HOME/pgsql CFLAGS=-O0\n(省略)\nchecking for icu-uc icu-i18n... no\nconfigure: error: Package requirements (icu-uc icu-i18n) were not met:\n\nNo package \u0026#39;icu-uc\u0026#39; found\nNo package \u0026#39;icu-i18n\u0026#39; found\n\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n\nAlternatively, you may set the environment variables ICU_CFLAGS\nand ICU_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ePKG_CONFIG_PATHという環境変数を設定してあげれば良いみたいです。\n以下のコマンドを実行すると、どう設定すればいいか教えてくれました。\u003c/p\u003e","title":"PostgreSQL16をソースコードからビルドしてみる"},{"content":"以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 なので今回はその時に調べた内容を記事にしてみました。\n次のコマンドでcontainerdをインストールできます。\n# yumにCentOS用のdockerリポジトリを追加する sudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする sudo yum install -y containerd.io # containerdのデフォルト設定ファイルを生成する sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service 参考 Using containerd without docker (Installing containerdの部分) ","permalink":"http://localhost:1313/posts/rocky-containerd/","summary":"\u003cp\u003e以前Kubernetesクラスタを構築するときに、Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。\nなので今回はその時に調べた内容を記事にしてみました。\u003c/p\u003e\n\u003cp\u003e次のコマンドでcontainerdをインストールできます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# yumにCentOS用のdockerリポジトリを追加する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# docker-ceリポジトリに含まれているcontainerd.ioのパッケージをインストールする\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo yum install -y containerd.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# containerdのデフォルト設定ファイルを生成する\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo sh -c \u003cspan class=\"s2\"\u003e\u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eそして最後にcontainerdを有効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl \u003cspan class=\"nb\"\u003eenable\u003c/span\u003e --now containerd.service\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"参考\"\u003e参考\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@DannielWhatever/using-containerd-without-docker-9d08332781b4\"\u003eUsing containerd without docker\u003c/a\u003e (Installing containerdの部分)\u003c/li\u003e\n\u003c/ul\u003e","title":"Rocky Linuxにcontainerdをインストールする方法"},{"content":"しばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。 今回はkubeadmを使ってk8sをインストールしようと思います。\n前提 ベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.3 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB kubeadmのインストール 以下の手順を参考にします。\nkubeadmのインストール 「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\nsudo swapoff -a ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。 RockyはRHEL系なのでfirewall-cmdを使って、Control Planeノードのポートを開放します。\nsudo firewall-cmd --add-port=6443/tcp --permanent sudo firewall-cmd --add-port=2379-2380/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent sudo firewall-cmd --add-port=10257/tcp --permanent sudo firewall-cmd --add-port=10259/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports 続いて各Workerノードのポートを開放します。\nsudo firewall-cmd --add-port=30000-32767/tcp --permanent sudo firewall-cmd --add-port=10250/tcp --permanent ポートが開放されたことを確認します。\nsudo firewall-cmd --reload sudo firewall-cmd --list-ports コンテナランタイムのインストール コンテナランタイムの手順を参考に、各ノードに設定をしていきます。\nインストールと設定の必須条件 全コンテナランタイムに共通の設定をしていきます。 まずはカーネルモジュールが起動時に自動でロードされるように設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 次のコマンドを実行してbr_netfilterとoverlayモジュールが読み込まれていることを確認します。\nlsmod | grep br_netfilter lsmod | grep overlay 続いて、ネットワーク周りのカーネルパラメータを設定します。\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system 以下のコマンドを実行して、net.bridge.bridge-nf-call-iptables、net.bridge.bridge-nf-call-ip6tables、net.ipv4.ip_forwardカーネルパラメーターが1に設定されていることを確認します。\nsysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward containerdのインストール Rocky Linuxでcontainerdをインストールする方法についてあまり情報がなかったので、とても苦労しました。 以下の記事を参考にしました。\nUsing containerd without docker (Installing containerdの部分) 次のコマンドでcontaierdをインストールします。\nsudo yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo sh -c \u0026#34;containerd config default \u0026gt; /etc/containerd/config.toml\u0026#34; systemd cgroupドライバーを構成するに記載されているように、/etc/containerd/config.tomlのssystemdCgroupの値を「false」から「true」に変更します。\nSystemdCgroup = true そして最後にcontainerdを有効化します。\nsystemctl enable --now containerd.service kubeadm, kubelet, kubectlのインストール kubeadm, kubelet, kubectlをインストールします。 日本語版だとbaserepoのurlの記述が古かったので、英語版を参考にしました。\nsudo sh -c \u0026#34;cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes name=Kubernetes baseurl=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/ enabled=1 gpgcheck=1 gpgkey=https://pkgs.k8s.io/core:/stable:/v1.30/rpm/repodata/repomd.xml.key exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni EOF\u0026#34; # SELinuxをpermissiveモードに設定する(効果的に無効化する) sudo setenforce 0 sudo sed -i \u0026#39;s/^SELINUX=enforcing$/SELINUX=permissive/\u0026#39; /etc/selinux/config sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16 Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\nsudo kubeadm join 192.168.10.121:6443 --token bccqut.hxu0wkyo2y04i88c \\ --discovery-token-ca-cert-hash sha256:b8db95c90e2d485ac499efb266aef624b464770cc89ff74b8a041fc0a2bab0b9 kubectlのインストール 先にkubectlをインストールします。 macOS上でのkubectlのインストールおよびセットアップ\ncurl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/darwin/arm64/kubectl.sha256\u0026#34; echo \u0026#34;$(cat kubectl.sha256) kubectl\u0026#34; | shasum -a 256 --check chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl sudo chown root: /usr/local/bin/kubectl 以下を~/.zshrcに記述することで、kubectlのエイリアスが作成され、タブ補完が効くようになります。\nalias k=kubectl autoload -Uz compinit \u0026amp;\u0026amp; compinit source \u0026lt;(kubectl completion zsh) kubeconfigの設定 kubectlを使ってk8sクラスタ操作できるようにするために、以下を実行します。\nmkdir -p $HOME/.kube scp nuc01:/etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 次のように表示されればOKです。\n$ % kubectl get pods No resources found in default namespace. アドオンのインストール CNIプラグインであるFlannelをインストールします。\nkubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml まとめ NUCを使ってk8sクラスタを組んでみました。Rocky Linuxへのcontainerdのインストールやkubernetes package repositoryの変更などいくつかはまりましたが、なんとかk8sクラスタを構築することができました。運用がんばるぞ！\n","permalink":"http://localhost:1313/posts/nuc-k8s/","summary":"\u003cp\u003eしばらく放置していたNUC上にk8sをインストールして、おうちクラスタを運用していこうと思います。\n今回はkubeadmを使ってk8sをインストールしようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/nuc-k8s/nuc.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"前提\"\u003e前提\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.3\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"kubeadmのインストール\"\u003ekubeadmのインストール\u003c/h2\u003e\n\u003cp\u003e以下の手順を参考にします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003ekubeadmのインストール\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e「始める前に」にSwapがオフであること、と記載がありますが、swapがオフになっていなかったので無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo swapoff -a\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ポートの開放\"\u003eポートの開放\u003c/h3\u003e\n\u003cp\u003ekubernetesのコンポーネントが互いに通信するために、\u003ca href=\"https://kubernetes.io/docs/reference/networking/ports-and-protocols/\"\u003eこれらのポート\u003c/a\u003eを開く必要があります。\nRockyはRHEL系なので\u003ccode\u003efirewall-cmd\u003c/code\u003eを使って、Control Planeノードのポートを開放します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=6443/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=2379-2380/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10257/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --add-port=10259/tcp --permanent\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e続いて各Workerノードのポートを開放します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-coonsole\" data-lang=\"coonsole\"\u003esudo firewall-cmd --add-port=30000-32767/tcp --permanent\nsudo firewall-cmd --add-port=10250/tcp --permanent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eポートが開放されたことを確認します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-console\" data-lang=\"console\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --reload\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"go\"\u003esudo firewall-cmd --list-ports\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"コンテナランタイムのインストール\"\u003eコンテナランタイムのインストール\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/\"\u003eコンテナランタイム\u003c/a\u003eの手順を参考に、各ノードに設定をしていきます。\u003c/p\u003e","title":"NUC上にk8sクラスタを構築する"},{"content":"ウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\n転職を考えたきっかけ 前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\n企業選びの軸 企業選びは以下の軸をもとに考えました。\n自社でサービスを開発・運用している 技術力の高いエンジニアが在籍している 先進的な技術を扱っている 上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\n転職に向けて行ったこと インフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\n関連する資格の取得 (AWS SAP、CKA) 個人ブログでの発信 簡単なWebアプリの作成 前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\nウォンテッドリーへの入社を決めた経緯 ウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\n選考を受ける前だったか、1次面接の後だったか覚えていませんが、Engineering HandbookとCulture Bookをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\nまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\n入社してからの感想 毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\nオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\nびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　今後ウォンテッドリーで取り組みたいこと 今後取り組みたいことは以下の通りです。\nKubernetes, PostgreSQLなどのアップグレード インフラの性能監視・運用改善・障害対応 Goを用いたツールの開発 前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\n上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\n","permalink":"http://localhost:1313/posts/wantedly/","summary":"\u003cp\u003eウォンテッドリーに入社して1ヶ月経ったので、色々と振り返ってみようと思います。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/wantedly/wantedly.jpeg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"転職を考えたきっかけ\"\u003e転職を考えたきっかけ\u003c/h2\u003e\n\u003cp\u003e前職ではややニッチなテーマに取り組んでいたこともあり、そのまま長く居続けても他の会社でやっていけるか不安でした。また、変化が早い時代なので、会社に依存せず個人でやっていけるだけの実力・スキルを身につけたいと考え、もっと技術力を伸ばせるような会社に移りたいと思うようになりました。\u003c/p\u003e\n\u003ch2 id=\"企業選びの軸\"\u003e企業選びの軸\u003c/h2\u003e\n\u003cp\u003e企業選びは以下の軸をもとに考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自社でサービスを開発・運用している\u003c/li\u003e\n\u003cli\u003e技術力の高いエンジニアが在籍している\u003c/li\u003e\n\u003cli\u003e先進的な技術を扱っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記の条件を満たすような会社であれば、もっと技術力を伸ばせると思ったからです。\u003c/p\u003e\n\u003ch2 id=\"転職に向けて行ったこと\"\u003e転職に向けて行ったこと\u003c/h2\u003e\n\u003cp\u003eインフラエンジニア / SRE職を希望していたので、主に以下のようなことを行いました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e関連する資格の取得 (AWS SAP、CKA)\u003c/li\u003e\n\u003cli\u003e個人ブログでの発信\u003c/li\u003e\n\u003cli\u003e簡単なWebアプリの作成\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職でPostgreSQL、Kubernetesを触る機会があったものの、AWSやTerraformの経験、それに本番環境の運用経験がなく苦労しました。実務での経験不足を補うために、AWSの資格を取得したり、個人ブログで今まで学んだことのアウトプットなどを行うようにしました。また、SRE職などだと自動化のツールなどをGoで書くこともあると思ったので、Goで簡単なTo-doアプリを作成したりしました。\u003c/p\u003e\n\u003ch2 id=\"ウォンテッドリーへの入社を決めた経緯\"\u003eウォンテッドリーへの入社を決めた経緯\u003c/h2\u003e\n\u003cp\u003eウォンテッドリーへはスカウト経由で入社しました。（Wantedly Visitに登録したら、ウォンテッドリーからスカウトが来てびっくりしました笑）カジュアル面談で話を聞いていると、PostgreSQLやKubernetesなど今まで培った経験を活かしつつ、新しい挑戦ができそうだったので、選考を受けてみようと思いました。\u003c/p\u003e\n\u003cp\u003e選考を受ける前だったか、1次面接の後だったか覚えていませんが、\u003ca href=\"https://docs.wantedly.dev/\"\u003eEngineering Handbook\u003c/a\u003eと\u003ca href=\"https://www.wantedly.com/companies/wantedly/post_articles/883691\"\u003eCulture Book\u003c/a\u003eをいただきました。まず、開発や会社の文化に関することがこのような形にまとめられているのが素敵だと思いました。そして、内容に関してもエンジニアリングに対して真摯に向き合う姿勢やエンジニアにとても理解のある会社だということが伝わってきて、こんな会社で働いてみたいと思うようになりました。（個人的にはCulture Bookの「変わるエンジニアの定義」が好きです。)\u003c/p\u003e\n\u003cp\u003eまた、2次選考として 1 day インターンに参加させていただきました。わずか1日のインターンシップではあるものの、チームメンバーがどんな人なのか、日々どんな業務に取り組んでいるのかなど実際に働くイメージがつき、その後安心して入社することができました。\u003c/p\u003e\n\u003ch2 id=\"入社してからの感想\"\u003e入社してからの感想\u003c/h2\u003e\n\u003cp\u003e毎日分からないことだらけですが、その分学ぶことが多くてとても充実しています。周りのエンジニアの方々は技術力が高くて、尊敬できる方ばかりです。\u003c/p\u003e\n\u003cp\u003eオンボーディングに関しては、研修や社内のドキュメントが整備されていて、スムーズに環境に馴染むことができました。分からないことがあるとすぐに聞ける雰囲気があり、ちょっとしたことでもSlackやHuddleで相談できて大変ありがたいです。週2出社なので、対面でのコミュニケーションもできて良い感じです。\u003c/p\u003e\n\u003cp\u003eびっくりしたことは、会議室の名前がジョジョの奇妙な冒険からつけられていること、白金台のランチの選択肢の少なさ、あとはエンジニアの1割がDvorak使いということですかね笑　\u003c/p\u003e\n\u003ch2 id=\"今後ウォンテッドリーで取り組みたいこと\"\u003e今後ウォンテッドリーで取り組みたいこと\u003c/h2\u003e\n\u003cp\u003e今後取り組みたいことは以下の通りです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eKubernetes, PostgreSQLなどのアップグレード\u003c/li\u003e\n\u003cli\u003eインフラの性能監視・運用改善・障害対応\u003c/li\u003e\n\u003cli\u003eGoを用いたツールの開発\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e前職だと実運用を経験していなかったので、システム基盤のアップグレードを経験したいという思いがあります。同様に、性能監視や運用改善、障害対応などインフラエンジニアとして求められている基本的な業務も一通り経験してみたいです。また、ウォンテッドリーのインフラチームは様々なツールをGoで実装しているので、それらの実装を理解し改善していけるだけの力をつけていきたいです。\u003c/p\u003e\n\u003cp\u003e上記以外にも直近不足している知識(NW、AWS、Terraform、Gitなど)が多いので、日々精進していく所存です！\u003c/p\u003e","title":"ウォンテッドリーに入社しました"},{"content":"Kubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\nなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\nwebhookとは? Alertmanagerのreceiverには以下が指定できます。\nEmail Opesgenie PagerDuty Pushover Slack AWS SNS VictorOps Webhook Wechat Telegram Webex Webhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。 外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\n例えば、以下のように設定します。\nreceivers: - name: \u0026#34;nginx\u0026#34; webhook_configs: - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39; webhookの連携先としてnginxを使う 今回はwebhookの連携先としてnginxを使用します。\nnginxを使って実現したいことは以下のとおりです。\nエンドポイントを用意する リクエスト内容を確認する nginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。 log_formatで$request_bodyを指定し、/にアクセスした時に$request_bodyがログとして標準出力に出るように設定しています。\nしかし、$request_bodyを有効化するにはproxy_passなどの後続処理が必要になります。なので、proxy_passで/trashというエンドポイントにリクエストを転送し、/trashで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\nThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\nhttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\nuser nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。nginx-svcというServiceも作成します。\napiVersion: v1 kind: ConfigMap metadata: name: nginx-configmap labels: app: nginx data: nginx.conf: | user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; # -------------------追加設定--------------------- log_format postdata escape=none $request_body; server { listen 8080; location / { access_log /dev/stdout postdata; proxy_pass http://127.0.0.1:8080/trash; } location /trash { access_log off; empty_gif; break; } } # ---------------------------------------------- sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } --- apiVersion: v1 kind: Service metadata: name: nginx-svc labels: app: nginx spec: selector: app: nginx ports: - name: nginx-http protocol: TCP port: 8080 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-configmap items: - key: nginx.conf path: nginx.conf 先程例にあったように、nginx-svcをエンドポイントしてAlertmanagerのWebhookを設定します。 そうすると、以下のようにリクエストボディとして送られたアラートの情報を確認することができます。(本来は以下のようにフォーマットされないです。ブログ用にフォーマットしています。)\n$ k logs nginx-6dcc55fd49-7kbpd ...(略)... { \u0026#34;receiver\u0026#34;:\u0026#34;nginx\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;alerts\u0026#34;:[ { \u0026#34;status\u0026#34;:\u0026#34;firing\u0026#34;, \u0026#34;labels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;annotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;startsAt\u0026#34;:\u0026#34;2023-08-13T03:48:56.603Z\u0026#34;, \u0026#34;endsAt\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;, \u0026#34;generatorURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\\u0026g0.tab=1\u0026#34;, \u0026#34;fingerprint\u0026#34;:\u0026#34;65b77eed2fe8b9c7\u0026#34; } ], \u0026#34;groupLabels\u0026#34;:{ \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34; }, \u0026#34;commonLabels\u0026#34;:{ \u0026#34;alertname\u0026#34;:\u0026#34;TargetDown\u0026#34;, \u0026#34;job\u0026#34;:\u0026#34;kube-proxy\u0026#34;, \u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;prometheus\u0026#34;:\u0026#34;monitoring/kube-prometheus-kube-prome-prometheus\u0026#34;, \u0026#34;service\u0026#34;:\u0026#34;kube-prometheus-kube-prome-kube-proxy\u0026#34;, \u0026#34;severity\u0026#34;:\u0026#34;warning\u0026#34; }, \u0026#34;commonAnnotations\u0026#34;:{ \u0026#34;description\u0026#34;:\u0026#34;100% of the kube-proxy/kube-prometheus-kube-prome-kube-proxy targets in kube-system namespace are down.\u0026#34;, \u0026#34;runbook_url\u0026#34;:\u0026#34;https://runbooks.prometheus-operator.dev/runbooks/general/targetdown\u0026#34;, \u0026#34;summary\u0026#34;:\u0026#34;One or more targets are unreachable.\u0026#34; }, \u0026#34;externalURL\u0026#34;:\u0026#34;http://kube-prometheus-kube-prome-alertmanager.monitoring:9093\u0026#34;, \u0026#34;version\u0026#34;:\u0026#34;4\u0026#34;, \u0026#34;groupKey\u0026#34;:\u0026#34;{}:{namespace=\\\u0026#34;kube-system\\\u0026#34;}\u0026#34;, \u0026#34;truncatedAlerts\u0026#34;:0 } まとめ Alertmanagerのwebhookをnginxに連携して、アラートの内容をログから確認できるようにしてみました。\n","permalink":"http://localhost:1313/posts/webhook-nginx/","summary":"\u003cp\u003eKubernetes上でAlertmanagerがちゃんと通知できるか、どんな内容が通知されているのか確認してみようとすると、連携するためのSlackが必要であったり、Emailを送信するにもメールサーバが必要だったりと、意外と気軽に試せないということがありました。\u003c/p\u003e\n\u003cp\u003eなので、今回はwebhookの機能を使ってNginxにリクエストを飛ばし、リクエストの内容をログから確認してみようと思います。\u003c/p\u003e\n\u003ch2 id=\"webhookとは\"\u003ewebhookとは?\u003c/h2\u003e\n\u003cp\u003eAlertmanagerのreceiverには以下が指定できます。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEmail\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.atlassian.com/software/opsgenie\"\u003eOpesgenie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.pagerduty.com/\"\u003ePagerDuty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://pushover.net/\"\u003ePushover\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://slack.com/intl/ja-jp\"\u003eSlack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://aws.amazon.com/jp/sns/\"\u003eAWS SNS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.splunk.com/en_us/about-splunk/acquisitions/splunk-on-call.html\"\u003eVictorOps\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eWebhook\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.wechat.com/ja/\"\u003eWechat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://telegram.org/\"\u003eTelegram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.webex.com/ja/index.html\"\u003eWebex\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWebhookとは特定のエンドポイントに対してHTTP POSTリクエストでアラートの情報を送信するというものです。\n外部サービスではないので、自分自身でエンドポイントを用意し、自分自身で後続の処理を実装する必要があります。\u003c/p\u003e\n\u003cp\u003e例えば、以下のように設定します。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ereceivers:\n- name: \u0026#34;nginx\u0026#34;\n  webhook_configs:\n  - url: \u0026#39;http://nginx-svc.default:8080/\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webhookの連携先としてnginxを使う\"\u003ewebhookの連携先としてnginxを使う\u003c/h2\u003e\n\u003cp\u003e今回はwebhookの連携先としてnginxを使用します。\u003c/p\u003e\n\u003cp\u003enginxを使って実現したいことは以下のとおりです。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eエンドポイントを用意する\u003c/li\u003e\n\u003cli\u003eリクエスト内容を確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003enginx.confの初期設定をベースにしていますが、そのままだとリクエスト内容を確認することができないので、設定を追加しました。\n\u003ccode\u003elog_format\u003c/code\u003eで\u003ccode\u003e$request_body\u003c/code\u003eを指定し、\u003ccode\u003e/\u003c/code\u003eにアクセスした時に\u003ccode\u003e$request_body\u003c/code\u003eがログとして標準出力に出るように設定しています。\u003c/p\u003e\n\u003cp\u003eしかし、\u003ccode\u003e$request_body\u003c/code\u003eを有効化するには\u003ccode\u003eproxy_pass\u003c/code\u003eなどの後続処理が必要になります。なので、\u003ccode\u003eproxy_pass\u003c/code\u003eで\u003ccode\u003e/trash\u003c/code\u003eというエンドポイントにリクエストを転送し、\u003ccode\u003e/trash\u003c/code\u003eで特に意味のない処理(1x1ピクセルのgifを返す)をしています。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe variable’s value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives when the request body was read to a memory buffer.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\"\u003ehttp://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003euser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;\n                      \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;\n                      \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;\n\n    access_log  /var/log/nginx/access.log  main;\n\n    # -------------------追加設定---------------------\n    log_format  postdata escape=none $request_body;\n\n    server {\n        listen   8080;\n        location / {\n            access_log /dev/stdout postdata;\n            proxy_pass http://127.0.0.1:8080/trash;\n        }\n        location /trash {\n            access_log off;\n            empty_gif;\n            break;\n        }\n    }\n    # ----------------------------------------------\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e上記の設定をConfigMapとして作成し、nginxのPodに対してConfigMapをマウントしてあげます。\u003ccode\u003enginx-svc\u003c/code\u003eというServiceも作成します。\u003c/p\u003e","title":"Alertmanagerのwebhookを試してみる"},{"content":"CronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。 主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\n一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。 なので、今回はそちらについて考えてみたいと思います。\nkube-state-metricsを活用する kube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。 kube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。 この方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\n※記事\nhttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511 https://www.giffgaff.io/tech/monitoring-kubernetes-jobs どのメトリクスを使い監視するか CronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。 また、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\nJobが完了するのはcompletions個のPodが正常終了した場合、もしくはbackoffLimit個のPodが異常終了した場合に限ります。\ncompletions completions個のPodが成功すると、Jobが完了したとみなされる デフォルトは1 backoffLimit 失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる デフォルトは6 そして、アラートを上げたいのはJobが失敗した時です。言い換えると、backoffLimit個のPodが異常終了したときにアラートを上げるということになります。 何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\nメトリクス 対応する項目 説明 kube_job_status_succeeded .status.succeeded Jobの管理下で正常終了したPodの数 kube_job_status_failed .status.failed Jobの管理下で異常終了したPodの数 kube_job_complete .status.conditions.type Jobが成功したかどうか kube_job_failed .status.conditions.type Jobが失敗したかどうか 参考: https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\nJobに関するメトリクスは複数ありますが、この中でも特にkube_job_failedを使ってアラートを上げるのが良さそうです。 以下の設定だと、Jobが失敗したときにアラートが上がります。\nkube_job_failed \u0026gt; 0 アラートが発火し続けてしまう問題 失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。 なので、JobのttlSecondsAfterFinishedを設定し、数分後にJobが削除されるようにします。\nttlSecondsAfterFinished 指定秒後にJobを削除できる CronJobのfailedJobsHistoryLimitを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\nfailedJobsHistoryLimit 失敗したJobを指定個数分残しておける デフォルトは1 まとめ 今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\n","permalink":"http://localhost:1313/posts/k8s-job-alert/","summary":"\u003cp\u003eCronJobは、指定したcronフォーマットに基づいて定期的にJobを実行するという機能です。\n主にバックアップの取得やメール送信など、定期的な処理を実行する際に便利です。\u003c/p\u003e\n\u003cp\u003e一方で、CronJobが失敗した際にどのように検知すべきかについては、あまり情報がありませんでした。\nなので、今回はそちらについて考えてみたいと思います。\u003c/p\u003e\n\u003ch2 id=\"kube-state-metricsを活用する\"\u003ekube-state-metricsを活用する\u003c/h2\u003e\n\u003cp\u003ekube-state-metricsとはKubernetesクラスタ内のリソースの状態をメトリクスとして提供してくれるというものです。\nkube-state-metricsではCronJobやJobの状態をメトリクスとして取得することができます。\nこの方式採用している記事が多かったので、こちらで検討を進めてみたいと思います。\u003c/p\u003e\n\u003cp\u003e※記事\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\"\u003ehttps://medium.com/@tristan_96324/prometheus-k8s-cronjob-alerts-94bee7b90511\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.giffgaff.io/tech/monitoring-kubernetes-jobs\"\u003ehttps://www.giffgaff.io/tech/monitoring-kubernetes-jobs\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どのメトリクスを使い監視するか\"\u003eどのメトリクスを使い監視するか\u003c/h2\u003e\n\u003cp\u003eCronJobはcronフォーマットで指定された時刻にJobを生成し、そのJobがPodを生成するという3層の親子構造になっています。\nまた、CronJobとJobの関係は1対多で、JobとPodの関係は1対多になります。\u003c/p\u003e\n\u003cp\u003eJobが完了するのは\u003ccode\u003ecompletions\u003c/code\u003e個のPodが正常終了した場合、もしくは\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了した場合に限ります。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecompletions\n\u003cul\u003e\n\u003cli\u003ecompletions個のPodが成功すると、Jobが完了したとみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ebackoffLimit\n\u003cul\u003e\n\u003cli\u003e失敗したと判断するまでの再試行回数で、この回数を超えるとJobは失敗とみなされる\u003c/li\u003e\n\u003cli\u003eデフォルトは6\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eそして、アラートを上げたいのはJobが失敗した時です。言い換えると、\u003ccode\u003ebackoffLimit\u003c/code\u003e個のPodが異常終了したときにアラートを上げるということになります。\n何個のPodが異常終了したのか監視することも可能だと思いますが、ここではJobのステータスを監視するのが適切かと思います。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eメトリクス\u003c/th\u003e\n          \u003cth\u003e対応する項目\u003c/th\u003e\n          \u003cth\u003e説明\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_succeeded\u003c/td\u003e\n          \u003ctd\u003e.status.succeeded\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で正常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_status_failed\u003c/td\u003e\n          \u003ctd\u003e.status.failed\u003c/td\u003e\n          \u003ctd\u003eJobの管理下で異常終了したPodの数\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_complete\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが成功したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ekube_job_failed\u003c/td\u003e\n          \u003ctd\u003e.status.conditions.type\u003c/td\u003e\n          \u003ctd\u003eJobが失敗したかどうか\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e参考: \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/job-metrics.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJobに関するメトリクスは複数ありますが、この中でも特に\u003ccode\u003ekube_job_failed\u003c/code\u003eを使ってアラートを上げるのが良さそうです。\n以下の設定だと、Jobが失敗したときにアラートが上がります。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekube_job_failed \u0026gt; 0\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"アラートが発火し続けてしまう問題\"\u003eアラートが発火し続けてしまう問題\u003c/h2\u003e\n\u003cp\u003e失敗したJobは削除されずに残り続けるので、アラートが発火し続けてしまいます。\nなので、Jobの\u003ccode\u003ettlSecondsAfterFinished\u003c/code\u003eを設定し、数分後にJobが削除されるようにします。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ettlSecondsAfterFinished\n\u003cul\u003e\n\u003cli\u003e指定秒後にJobを削除できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCronJobの\u003ccode\u003efailedJobsHistoryLimit\u003c/code\u003eを設定するという方法も思いつきましたが、0にしてしまうとそもそもアラートが上がらないと思うので、こちらは1のままにしておきました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efailedJobsHistoryLimit\n\u003cul\u003e\n\u003cli\u003e失敗したJobを指定個数分残しておける\u003c/li\u003e\n\u003cli\u003eデフォルトは1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e今回はkube-state-metricsを活用して、CronJobが失敗した時のアラートを設定しました。CronJob失敗時にアラートを上げる方法についてはあまり参考になる記事がなく、私なりに考えてみました。他にもっといい方法をご存知の方は教えていただけるとありがたいです。\u003c/p\u003e","title":"KubernetesのCronJobが失敗したときにアラートをあげる"},{"content":"Linuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\n接続元での設定 接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\nssh-keygen scp ~/id_rsa.pub username@server:~/ 接続先の設定 接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\nmkdir ~/.ssh chmod 700 ~/.ssh cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys 公開鍵認証を有効化し、パスワード認証を無効化します。\nsudo vi /etc/ssh/sshd_config --- PubkeyAuthentication yes PasswordAuthentication no sshdを再起動します。\nsystemctl restart sshd ","permalink":"http://localhost:1313/posts/pubkey-auth/","summary":"\u003cp\u003eLinuxでの公開鍵認証の設定をよく忘れてしまうので、備忘録としてメモを残しておきます。\u003c/p\u003e\n\u003ch2 id=\"接続元での設定\"\u003e接続元での設定\u003c/h2\u003e\n\u003cp\u003e接続元で鍵を生成し、公開鍵を接続先のサーバーへコピーします。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003essh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003escp ~/id_rsa.pub username@server:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"接続先の設定\"\u003e接続先の設定\u003c/h2\u003e\n\u003cp\u003e接続先のサーバーで公開鍵の情報をauthorized_keysに登録し、適切な権限を設定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ecat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003echmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵認証を有効化し、パスワード認証を無効化します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esudo vi /etc/ssh/sshd_config\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePubkeyAuthentication yes\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ePasswordAuthentication no\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003esshdを再起動します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003esystemctl restart sshd\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"Linuxで公開鍵認証をする"},{"content":"k8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\n学習環境 Minikube Kind プロダクション環境 kubeadm kops kubespray ※各ツールの違いについてはこちら\n今回はその中でもkubesprayというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\nちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\n構築 前提:\nベアメタル(Intel NUC11PAHi5)上に構築 Control Planex1台とWorkerx3台の4台構成 OSはRocky Linux9.1 ルーター側の設定で固定IPを割り当て 各ノードのスペックは以下 CPU メモリ ストレージ 4コア 16GB 500GB ssh公開認証の設定 手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。 ssh-keygenのパスワードには空文字を指定します。\nkkato@bastion:~$ ssh-keygen kkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/ 公開鍵の情報を各ノードのauthorized_keysに追記します。\nkkato@nuc01:~$ mkdir ~/.ssh kkato@nuc01:~$ chmod 700 /.ssh kkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys kkato@nuc01:~$ chmod 600 ~/.ssh/authorized_keys /etc/hostsの編集 手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\nkkato@bastion:~$ cat /etc/hosts --- 192.168.10.121 nuc01 192.168.10.122 nuc02 192.168.10.123 nuc03 192.168.10.124 nuc04 ユーザーの設定 各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\nkkato@nuc01:~$ sudo visudo --- kkato ALL=NOPASSWD:ALL Firewallの無効化 各ノードのFirewallを無効化します。\nkkato@nuc01:~$ sudo systemctl stop firewalld kkato@nuc01:~$ sudo systemctl disable firewalld kkato@nuc01:~$ sudo systemctl status firewalld kubesprayのダウンロード kubesprayのgitリポジトリをクローンし、最新バージョンのブランチに移動します。\nkkato@bastion:~$ git clone https://github.com/kubernetes-sigs/kubespray.git kkato@bastion:~$ cd kubespray kkato@bastion:~/kubespray$ git branch -a kkato@bastion:~/kubespray$ git switch remotes/origin/release-2.21 --detach 必要なパッケージのインストール 必要なパッケージをインストールします。\nkkato@bastion:~/kubespray$ sudo pip3 install -r requirements.txt インベントリファイルの編集 Ansibleのインベントリファイルの雛形を作成します。\nkkato@bastion:~/kubespray$ cp -rfp inventory/sample inventory/mycluster kkato@bastion:~/kubespray$ declare -a IPS=(192.168.10.xxx 192.168.10.xxx 192.168.10.xxx 192.168.10.xxx) kkato@bastion:~/kubespray$ CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]} 作成されたインベントリファイルを編集します。\nkkato@bastion:~/kubespray$ cat inventory/mycluster/hosts.yml --- all: hosts: nuc01: ansible_host: 192.168.10.121 ip: 192.168.10.121 access_ip: 192.168.10.121 nuc02: ansible_host: 192.168.10.122 ip: 192.168.10.122 access_ip: 192.168.10.122 nuc03: ansible_host: 192.168.10.123 ip: 192.168.10.123 access_ip: 192.168.10.123 nuc04: ansible_host: 192.168.10.124 ip: 192.168.10.124 access_ip: 192.168.10.124 children: kube_control_plane: hosts: nuc01: kube_node: hosts: nuc02: nuc03: nuc04: etcd: hosts: nuc01: k8s_cluster: children: kube_control_plane: kube_node: calico_rr: hosts: {} inventory/mycluster/group_vars/all/all.ymlやinventory/mycluster/group_vars/k8s_cluster/k8s-cluster.ymlのパラメータを確認・変更します。 以下では、kubectlを手元のPCにインストールする、~/.kube/configの設定ファイルを作成するように設定しています。\nkkato@bastion:~/kubespray$ diff -r inventory/sample/group_vars/k8s_cluster/k8s-cluster.yml inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 256c256 \u0026lt; # kubeconfig_localhost: false --- \u0026gt; kubeconfig_localhost: true 260c260 \u0026lt; # kubectl_localhost: false --- \u0026gt; kubectl_localhost: true kubespray実行 kubesprayを実行し、failed=0になっていることを確認します。\nkkato@bastion:~/kubespray$ ansible-playbook -i inventory/mycluster/hosts.yaml --become --become-user=root cluster.yml --- PLAY RECAP ************************************************************************************************************************************************ localhost : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 nuc01 : ok=727 changed=67 unreachable=0 failed=0 skipped=1236 rescued=0 ignored=7 nuc02 : ok=506 changed=34 unreachable=0 failed=0 skipped=755 rescued=0 ignored=1 nuc03 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 nuc04 : ok=506 changed=34 unreachable=0 failed=0 skipped=754 rescued=0 ignored=1 kubectlの設定 kubectlがインスールされていることを確認します。そして、kubeconfigを~/.kube/configに配置します。\nkkato@bastion:~/kubespray$ ls /usr/local/bin/ | grep kubectl kubectl kkato@bastion:~/kubespray$ cp -ip inventory/mycluster/artifacts/admin.conf ~/.kube/config kubectlでタブ補完がされるように設定します。また、毎回kubectlと打つのはめんどくさいので、kというエイリアスを設定します。\nkkato@bastion:~$ sudo apt install bash-completion kkato@bastion:~$ cho \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl kkato@bastion:~$ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc kkato@bastion:~$ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc 動作確認 kubectlコマンドを実行すると、先程設定したノードが認識されていることがわかります。\nkkato@bastion:~$ k get nodes NAME STATUS ROLES AGE VERSION nuc01 Ready control-plane 5m23s v1.25.6 nuc02 Ready \u0026lt;none\u0026gt; 4m8s v1.25.6 nuc03 Ready \u0026lt;none\u0026gt; 4m20s v1.25.6 nuc04 Ready \u0026lt;none\u0026gt; 4m7s v1.25.6 まとめ 前回はkubeadmを使ってk8sクラスタを構築しましたが、今回はkubesprayを使ってk8sクラスタを構築してみました。kubeadmよりも簡単にk8sクラスタを構築できて、すごく便利でした。\n参考 GitHub - kubernetes-sigs/kubespray: Deploy a Production Ready Kubernetes Cluster kubesprayを使ったKubernetesのインストール ","permalink":"http://localhost:1313/posts/kubespray/","summary":"\u003cp\u003ek8s構築ツールはいろいろありますが、公式ドキュメントでは以下が紹介されています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/learning-environment/\"\u003e学習環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eMinikube\u003c/li\u003e\n\u003cli\u003eKind\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/ja/docs/setup/production-environment/\"\u003eプロダクション環境\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003ekubeadm\u003c/li\u003e\n\u003cli\u003ekops\u003c/li\u003e\n\u003cli\u003ekubespray\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e※各ツールの違いについては\u003ca href=\"https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md\"\u003eこちら\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e今回はその中でも\u003ca href=\"https://github.com/kubernetes-sigs/kubespray\"\u003ekubespray\u003c/a\u003eというツールを使ってk8sクラスタを構築してみようと思います。kubeadmは1台ずつインストールを実施するのに対し、kubesprayはAnsibleを使い、各ノードで一斉にインストールを実施します。なので、kubesprayは台数が多いときに便利です。\u003c/p\u003e\n\u003cp\u003eちなみに、kubesprayは内部でkubeadmを使っているので、kubespray = kubeadm + Ansibleという感じです。また、kubesprayを使うと、コンテナランタイム(デフォルトはcontainerd)やPod間通信のネットワークプラグイン(デフォルトはcalico)などが自動でインストールされるので、非常に便利です。\u003c/p\u003e\n\u003ch2 id=\"構築\"\u003e構築\u003c/h2\u003e\n\u003cp\u003e前提:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eベアメタル(Intel NUC11PAHi5)上に構築\u003c/li\u003e\n\u003cli\u003eControl Planex1台とWorkerx3台の4台構成\u003c/li\u003e\n\u003cli\u003eOSはRocky Linux9.1\u003c/li\u003e\n\u003cli\u003eルーター側の設定で固定IPを割り当て\u003c/li\u003e\n\u003cli\u003e各ノードのスペックは以下\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eCPU\u003c/th\u003e\n          \u003cth\u003eメモリ\u003c/th\u003e\n          \u003cth\u003eストレージ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e4コア\u003c/td\u003e\n          \u003ctd\u003e16GB\u003c/td\u003e\n          \u003ctd\u003e500GB\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"ssh公開認証の設定\"\u003essh公開認証の設定\u003c/h3\u003e\n\u003cp\u003e手元のPCからパスワードなしでssh接続できるように公開鍵認証の設定をします。\nssh-keygenのパスワードには空文字を指定します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ ssh-keygen\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ scp ~/.ssh/id_rsa.pub 192.168.10.xxx:~/\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e公開鍵の情報を各ノードのauthorized_keysに追記します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ mkdir ~/.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e700\u003c/span\u003e /.ssh\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ cat id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@nuc01:~$ chmod \u003cspan class=\"m\"\u003e600\u003c/span\u003e ~/.ssh/authorized_keys\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"etchostsの編集\"\u003e/etc/hostsの編集\u003c/h3\u003e\n\u003cp\u003e手元のPCから各ノードへホスト名で接続できるように、/etc/hostsを編集します。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ekkato@bastion:~$ cat /etc/hosts\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e---\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.121 nuc01\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.122 nuc02\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.123 nuc03\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e192.168.10.124 nuc04\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"ユーザーの設定\"\u003eユーザーの設定\u003c/h3\u003e\n\u003cp\u003e各ノードのユーザーがパスワードなしでsudo実行できるよう設定します。\u003c/p\u003e","title":"kubesprayでk8sクラスタを構築する"},{"content":"最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。 Control Planeノードx1 Workerノードx3の構成です。\n準備 準備したものは以下のとおりです。\nアイテム 個数 Raspberry Pi 4 Model B / 4GB 4 Raspberry Pi PoE+ HAT 4 ケース 1 microSD 64GB 4 スイッチングハブ 1 LANケーブル 0.15m 4 LANケーブル 1m 1 SDカードリーダー 1 HDMI変換アダプター 1 PoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\nOSの設定 OSのインストール 手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\n$ sudo apt install rpi-imager そして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\n$ rpi-imager microSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\n$ sudo spy update $ sudo apt upgrade -y 新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\n$ sudo adduser kkato $ sudo usermod -aG sudo kkato $ sudo visudo --- kkato ALL=NOPASSWD: ALL 固定IPの設定 OS側で固定IPを設定する方法もありますが、今回はルーター側で設定してみたいと思います。 まずは以下のコマンドを使って、MACアドレスを確認します。(以下だと、eth0のdc:a6:32:70:52:2aです。)\n$ ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2a brd ff:ff:ff:ff:ff:ff 3: wlan0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether dc:a6:32:70:52:2b brd ff:ff:ff:ff:ff:ff Aterm WG1200HS4というルーターを使っており、http://aterm.me/から固定IPを設定できます。ここで先ほど確認したMACアドレスと、固定したいIPアドレスを指定します。その後、ルーターを再起動し、設定が反映されているか確認します。 手元のPCからきちんと設定されているか確認します。(111~114がラズパイです。)\n$ arp -an ? (192.168.10.111) at dc:a6:32:70:52:2a [ether] on wlp0s20f3 ? (192.168.10.113) at e4:5f:01:e2:56:aa [ether] on wlp0s20f3 ? (192.168.10.114) at e4:5f:01:e2:57:88 [ether] on wlp0s20f3 ? (192.168.10.112) at e4:5f:01:e2:57:98 [ether] on wlp0s20f3 ? (192.168.10.1) at 80:22:a7:26:71:5c [ether] on wlp0s20f3 kubeadmのインストール 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 コンテナランタイム kubeadmのインストール ポートの開放 kubernetesのコンポーネントが互いに通信するために、これらのポートを開く必要があります。\nufwコマンドを使って、Control Planeノードのポートを開放します。\n# Control Planeノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 6443/tcp $ sudo ufw allow 2379:2380/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 10259/tcp $ sudo ufw allow 10257/tcp ポートが開放されたことを確認します。\n$ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 6443/tcp ALLOW Anywhere 2379:2380/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 10259/tcp ALLOW Anywhere 10257/tcp ALLOW Anywhere 続いて各Workerノードのポートを開放します。\n# 各Workerノードで実行 $ sudo ufw enable $ sudo ufw allow 22/tcp $ sudo ufw allow 10250/tcp $ sudo ufw allow 30000:32767/tcp ポートが開放されたことを確認します。\n# 各Workerノードで実行 $ sudo ufw status Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere 10250/tcp ALLOW Anywhere 30000:32767/tcp ALLOW Anywhere コンテナランタイムのインストール コンテナランタイムとはkubernetesノード上のコンテナとコンテナイメージを管理するためのソフトウェアです。\n2023年5月現在では、containeredやCRI-Oなどがコンテナランタイムとしてサポートされています。今回はcontainerdをインストールしようと思います。\nKubernetes supports container runtimes such as containerd, CRI-O, and any other implementation of the Kubernetes CRI (Container Runtime Interface).\nまずはカーネルモジュールを起動時に自動でロードするに設定します。overlayはコンテナに必要で、br_netfilterはPod間通信のために必要です。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter 続いて、ネットワーク周りのカーネルパラメータを設定します。以下を設定することにより、iptablesを使用してブリッジのトラフィック制御が可能になります。\n# 各ノードで実行 $ cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF $ sudo sysctl --system 最後にcontainerdをインストールします。\n# 各ノードで実行 $ sudo apt install containerd -y kubeadm, kubelet, kubectlのインストール aptのパッケージ一覧を更新し、Kubernetesのaptリポジトリを利用するのに必要なパッケージをインストールします。\n# 各ノードで実行 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl Google Cloudの公開鍵をダウンロードします。\n# 各ノードで実行 $ sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg Kubernetesのaptリポジトリを追加します。\n# 各ノードで実行 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list aptのパッケージ一覧を更新し、kubelet、kubeadm、kubectlをインストールします。そしてバージョンを固定します。\n# 各ノードで実行 $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl kubernetesクラスタの作成 以下の手順を参考にします。\nkubeadmを使用したクラスターの作成 kubectlのインストールおよびセットアップ Control Planeノードのデプロイ kubeadm initコマンドを使ってControl Planeノードをデプロイします。\n# Control Planeノードで実行 $ sudo kubeadm init --- Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: アドオンのインストール CNIプラグインであるFlannelをインストールします。\nhttps://github.com/flannel-io/flannel#deploying-flannel-manually\n$ kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml Workerノードのデプロイ kubeadm joinコマンドを使って、Workerノードをデプロイします。\n# 各Workerノードで実行 $ sudo kubeadm join 10.168.10.111:6443 --token s0px1g.7s2e6kwrj5qaiysr \\ --discovery-token-ca-cert-hash sha256:bbcfefdab5e92525d070ff0f7a8de077d72bad39f897193a288486f76462424d kubectlのインストール kubectlのバイナリをダウンロードします。\n# 手元のPCで実行 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; バイナリを実行可能にします。\n# 手元のPCで実行 $ chmod +x ./kubectl kubectlをPATHの中に移動します。\n# 手元のPCで実行 $ sudo mv ./kubectl /usr/local/bin/kubectl kubectlのタブ補完を設定します。\n# 手元のPCで実行 $ sudo dnf install bash-completion $ echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ kubectl completion bash \u0026gt;/etc/bash_completion.d/kubectl $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc kubeconfigの設定 kubeadm initコマンド実行後に表示された説明に沿って、kubeconfigを設定します。\n# 手元のPCで実行 $ mkdir -p $HOME/.kube $ scp raspi01:/etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 接続確認 k8sクラスタに接続できることを確認します。\n# 手元のPCで実行 $ k get pods No resources found in default namespace. まとめ ラズパイを使ってk8sクラスタを組んでみました。ずっとお家k8sクラスタを構築してみたいと思っていたので、やっと実現できてよかったです。k8sの構築方法を一通り体験したので、これでk8sを完全理解したと言えますね。\n","permalink":"http://localhost:1313/posts/raspi-k8s/","summary":"\u003cp\u003e最近ラズパイを手に入れたので、kubeadmを使ってk8sクラスタを組んでみたいと思います。\nControl Planeノードx1 Workerノードx3の構成です。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-cluster.jpg\"\u003e\u003c/p\u003e\n\u003ch2 id=\"準備\"\u003e準備\u003c/h2\u003e\n\u003cp\u003e準備したものは以下のとおりです。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eアイテム\u003c/th\u003e\n          \u003cth\u003e個数\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/5680\"\u003eRaspberry Pi 4 Model B / 4GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://www.switch-science.com/products/7172?_pos=1\u0026amp;_sid=e013ece27\u0026amp;_ss=r\"\u003eRaspberry Pi PoE+ HAT\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/8DQ2Vjn\"\u003eケース\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/1a7lXpn\"\u003emicroSD 64GB\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/6lrvPog\"\u003eスイッチングハブ\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/cSs0irO\"\u003eLANケーブル 0.15m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e4\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/0IejUmF\"\u003eLANケーブル 1m\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/4oTN3E9\"\u003eSDカードリーダー\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003ca href=\"https://amzn.asia/d/a8TZ1OH\"\u003eHDMI変換アダプター\u003c/a\u003e\u003c/td\u003e\n          \u003ctd\u003e1\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003ePoE(Power over Ethernet)+ HATを使うと、LANケーブルから電源供給できるのでとても便利です。今回はPoE+ HATを使っているので、スイッチングハブもPoE対応のものを購入しています。ラズパイのOSをSDカードにインストールする必要があるので、SDカードリーダーも購入しました。あとは、ディスプレイと繋ぐときにmicro HDMIに変換するためのアダプタも購入しました。\u003c/p\u003e\n\u003ch2 id=\"osの設定\"\u003eOSの設定\u003c/h2\u003e\n\u003ch3 id=\"osのインストール\"\u003eOSのインストール\u003c/h3\u003e\n\u003cp\u003e手元のPCはUbuntu 22.04 LTSなので、以下のコマンドでRaspberry Pi Imagerをインストールします。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eそして、microSDカード4枚全てにUbuntu Server 22.10 (64-bit)を焼きます。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ rpi-imager\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/raspi-k8s/raspi-imager.png\"\u003e\u003c/p\u003e\n\u003cp\u003emicroSDカードを差し込み、ディスプレイ(micro HDMI)とキーボード(USB)を接続し、OSの初期設定を行います。初期ユーザー名とパスワードはubuntuです。パッケージを最新にしておきます。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo spy update\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ sudo apt upgrade -y\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e新しくユーザを作成し、ユーザにsudo権限を付与します。sudoをパスワードなしでできるように追加の設定もします。\u003c/p\u003e","title":"Raspberry Pi上にk8sクラスタを構築する"},{"content":"2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\nなぜOMSCSを始めたのか 実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\n専門的な知識を身につける 私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\n海外で就職する 実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\n実際どうだったか 正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\nどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\nまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\n最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない 専門分野のコースは全てB以上の成績を収めなければならない 合計GPAが3.0/4.0以上でなければならない どんな授業を受けたのか OMSCSではSpecialization*1といって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\n学期 受講したコース 難易度 作業量 Fall 2020 CSE6040 Computing for Data Anlysis 易しい 10時間/週 Fall 2020 ISYE6501 Introduction to Analytics Modeling 普通 15時間/週 Summer 2021 CS6300 Software Development Process 普通 10時間/週 Fall 2021 CS6250 Computer Networks 普通 10時間/週 Fall 2021 CS7646 Machine Learning for Trading 普通 15時間/週 Spring 2022 CS6035 Introduction to Information Security 普通 15時間/週 Spring 2022 CS6200 Introduction to Operating Systems 難しい 20時間/週 Summer 2022 CS6262 Network Security 普通 15時間/週 Fall 2022 CS6515 Introduction to Graduate Algorithms 難しい 15時間/週 Fall 2022 CS9903-O13 Quantum Computing 易しい 10時間/週 受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており*2、定期的に追加・更新されます。また、OMSCSにはOMSCentral*3という非公式のレビューサイトがあるので、そちらも参考にしてみてください。\nCSE6040 Computing for Data Anlysis OMSA限定のコースになります。データサイエンスで必要となるPythonとそのライブラリ(numpy, scipay, pandas)の使い方が学べるので、データサイエンス初心者にぴったりのコースです。講義も課題もしっかり整理されていて、とても分かりやすかったです。\nGrade distribution:\nNotebooks(x15): 50% Midterm 1: 10% Midterm 2: 15% Final: 25% ISYE6501 Introduction to Analytics Modeling こちらはOMSAのコースですが、OMSCSの生徒も受講できます。基礎的な統計モデル(Suppor Vector Machines、K-Nearest Neighbors、K-Means Clusteringなど)について学習します。課題のほとんどはRで、Rを使ったことがなかったので、結構時間がかかりました。採点は生徒同士で行うので、かなりばらつきがあります。課題と授業の内容と乖離があり、テストでは思うように点が取れず苦労しました。\nGrade distribution:\nHomework(x15): 15% Course Project: 8% Midterm 1: 25% Midterm 2: 25% Final: 25% Syllabus Quiz: 2% CS6300 Software Development Process このコースでは、ソフトウェア開発手法(ウォーターフォール、アジャイル、プロトタイプ、スパイラル)やテスト手法(ブラックボックス、ホワイトボックス)、バージョン管理、UMLなどソフトウェア工学全般について学びます。課題は主にJavaを使いますが、GitやJUnit、UMLを書く課題もあります。グループプロジェクトでは3, 4人のチームを組み、Androidアプリを作成しました。幸いチームメンバはとても協力的だったので、スムーズにプロジェクトを終えることができました。\nGrade distribution:\nAssignments(x6): 44% Individual Project: 25% Group Project: 18% Collaboration (グループプロジェクトでチームメンバーから評価される): 10% Participation (Ed Discussionでの発言、Participation Quizなど): 3% CS6250 Computer Networks このコースでは、TCPやUDPの基礎知識や、ルーティング・プロトコル(経路制御アルゴリズム、RIP、OSPF、BGP)、ルーターの仕組み、Software Defined Networkingなどについて学びます。課題はSpanning Tree Protocol、Distance Vector Routing、SDN Firewallなどを実際にPythonで実装します。授業のビデオは棒読みで分量も多く眠気を誘ってきますが、課題の手順はかなり明確に説明されているので良かったです。マスタリングTCP/IPを読んで補足的に勉強しました。\nGrade Distribution:\nAssignments(x5): 66% Exam 1: 12% Exam 2: 12% Quizzes: 10% Extra credit: 3% CS7646 Machine Learning for Trading このコースでは、線型回帰、Q-Learning、k-Nearest Neighbor、回帰木などの統計手法を、どのように株取引に応用できるか学習します。統計手法はもちろんのこと、テクニカル分析などで使われるSimple Moving Average、Bollinger Bands、Stochastic Indicatorなどについても学びます。課題では過去の株取引のデータを渡され、お題にあったモデルをPythonで実装し、その考察をレポートに書いて提出します。個人的には課題がとても楽しく、内容も難しすぎず易しすぎず、お気に入りのコースの1つです。\nGrade Distribution:\nProjects(x8): 73% Exams(x2): 25% Surveys: 2% Extra credit: 2% CS6035 Introduction to Information Security このコースでは、ソフトウェア、OS、データベースのセキュリティや暗号に関するアルゴリズム/プロトコル、リスクマネジメントについて学習します。授業で習うこととプロジェクトに必要な知識・能力に乖離があり、プロジェクトが80%と多くの比重を占めるので、プロジェクト優先で取り組むのが良さそうです。課題ではC、Python、Java、HTML/JavaScript/PHP、SQLなど様々な知識が必要になりますが、課題をこなしながらキャッチアップすることは十分可能です。課題ではスタックオーバーフローを実装したり、Cuckooというツールでマルウェア解析したり、ウェブサイトにXSSやSQLインジェクションを仕掛けたりと結構楽しい課題が多かったです。\nGrade distribution:\nProjects(x4): 80% Quizzes(x4): 10% Exams(x2): 10% CS6200 Introduction to Operating Systems このコースでは、プロセスやプロセスマネジメント、スレッド、MutexやSemaphoreなどを使った並行性、メモリ管理、仮想化などについて学習します。課題では、ファイルを転送するクライアント・サーバ、キャシュサーバー、プロキシサーバーの実装をCで行ったり、gRPCの実装をC++を行ったりと、C/C++の前提知識がないとかなり大変です。私はC/C++を触ったことがほとんどなかったので、とても苦労しました。(まさか誕生日に徹夜することになるとは\u0026hellip;)しかし、CSにおいてとても重要な知識になるので、個人的にはOMSCSにおけるmust-takeだと思っています。\nGrade distribution:\nParticipation: 5% Projects(x3): 45% Midterm Exam: 25% Final Exam: 25% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS6262 Network Security このコースでは、DDoSやWebのセッションマネジメント、マルウェア解析、ボットネット検出などについて学びます。CS6035とかなり似ており、こちらもプロジェクトが80%と多くの比重を占めます。課題では、VirtualBoxのディスクイメージが配られ、様々なツール(nmapコマンド、Metasploit、John the Ripper、cewl、Cuckoo、Wiresharkなど)を駆使してポートスキャンやパスワード解析、権限奪取、マルウェア解析、XSS、ボットネット検出などを行います。かなり実践的なコースとなっており、CS6035と同じく結構楽しく課題に取り組めました。私は前提知識が少ない分時間がかかりましたが、地道に取り組めば必ず解けると思います。\nGrade distribution: Quizzes: 10% Projects(x5): 80% Exam: 10% Extra credit: 5%\nCS6515 Introduction to Graduate Algorithms このコースでは、Dynamic Programming、Divide and Conquer、RSA、グラフ理論, Linear Programming, NP完全問題について学習します。このコースでは、Study Groupを作って勉強することが推奨されているので、私はタイムゾーンが近い韓国人とマレーシア人の方と一緒にわからないところを質問し合ったり、情報共有するようにしました。また、このコースでは回答時の「フォーマット」がすごく重視されるので、宿題でその「フォーマット」に慣れておくようにしました。過去の生徒がきれいにまとめてくれたノート(Joves Notes)があり、Joves Notesに答えが載っている問題は全て解くようにしました。\nGrade distribution:\nHomework(x8): 12%. Polls: 4% Coding Projects(x3): 9%. Logistic quizzes: 3%. Exams(best 3 out of 4): 72% ※Curveありです。85%以上でA、65%以上でBくらいだと思います。 CS9903-O13 Quantum Computing このコースでは、Single Qubit Gates、Multi-Qubit Gatesや線形代数、量子もつれ、基礎的なアルゴリズム(Deusch-Joza Algorithm, Bernstein-Vazirani Algorithm, Grover\u0026rsquo;s Alogorithm, Simon\u0026rsquo;s Algorithm, Shor\u0026rsquo;s Algorithm)について学習します。課題ではQiskitを用いて、実際にいくつかのアルゴリズムを実装します。Qiskitのドキュメントを参考に課題を進め、分からないところはTAに質問するようにしました。量子コンピュータということでかなり難しいと予想していましたが、量子コンピュータに対する前提知識がなくても十分Aを取ることは可能だと思います。\nGrade distribution:\nReviews(x5): 20% Midterm: 20% Final: 20% Labs(x4): 40% まとめ OMSCSを始めた理由や各授業の内容、その感想などをご紹介させていただきました。ほとんどCSを学んだことがない私にとってはかなり大変でしたが、CSを学ぶ良い機会となりました。とはいえすぐに実務に直結するような内容はあまりないので、後になってじわじわ役に立つ知識という印象です(役に立ってくれるといいな)。なので学部でCSを学んでいた方が取得するメリットはあまりないと思いますが、私のように今までちゃんとCSを学んだことがない方や改めてCSを学び直したい方にはおすすめかなと思います。\n参考 *1 Specializations *2 Current Courses *3 OMSCentral\n","permalink":"http://localhost:1313/posts/omscentral/","summary":"\u003cp\u003e2020年8月にジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)に入学し、2022年12月に卒業しました。今回は入学から卒業までを振り返ってみようと思います。\u003c/p\u003e\n\u003ch2 id=\"なぜomscsを始めたのか\"\u003eなぜOMSCSを始めたのか\u003c/h2\u003e\n\u003cp\u003e実は途中でOMSAからOMSCSに編入していたりしますが、OMSCSを始めた主な目的は以下です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e専門的な知識を身につける\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e私は物理学の学士課程を卒業していますが、物理を学ぶと選択肢は広がるものの少し中途半端なんですよね。例えば、機械系に行きたいとすると機械工学の学生でいいじゃん、電子系に行きたいとすると電子工学の学生でいいじゃん、IT系に行きたいとすると情報系の学生でいいじゃん、となってしまいます。なので、物理学＋αでより専門的な知識を身につけて、今後のキャリアアップに役立てたいと考えました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e海外で就職する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e実は私はカナダの大学で学士号を取得していますが、卒業当時の私は現地就職するだけの自信と実力がありませんでした。国際的に評価されている大学の修士号であれば、海外で就職するときもプラスに働くと思い、OMSCSを始めることにしました。\u003c/p\u003e\n\u003ch2 id=\"実際どうだったか\"\u003e実際どうだったか\u003c/h2\u003e\n\u003cp\u003e正直かなり大変でした。コロナで家にいる時間も多かったですが、平日の仕事終わりと週末は基本的に家でずっと勉強していました。遊びに誘われることもありましたが、毎回断っていたら誰からも誘われなくなりました笑\u003c/p\u003e\n\u003cp\u003eどれくらいの時間が必要かというと、前提知識があるかどうかにもよると思いますが、1コースにつき週10-20時間は必要だと思います。ちなみに私は基本的に1学期に2コース取っていたので、休む時間がほとんどありませんでした。\u003c/p\u003e\n\u003cp\u003eまた、卒業には以下の条件があり、良い成績をとらないと卒業できないというプレッシャーがありました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e最初の12ヶ月でfundamental courseを最低2つ履修し、B以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e専門分野のコースは全てB以上の成績を収めなければならない\u003c/li\u003e\n\u003cli\u003e合計GPAが3.0/4.0以上でなければならない\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"どんな授業を受けたのか\"\u003eどんな授業を受けたのか\u003c/h2\u003e\n\u003cp\u003eOMSCSではSpecialization\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003eといって専門分野を決める必要があるのですが、私はComputing Systemsにしました。その理由としては配属された部署がデータベースや分散システムなどのミドルウェアを扱うところだったから、また低レイヤーの技術に興味があったからです。OMSCSでは10コース履修する必要がありますが、そのうち5, 6コースを自分の専門分野から履修しなければなりません(いわゆる必修科目)。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e受講したコース\u003c/th\u003e\n          \u003cth\u003e難易度\u003c/th\u003e\n          \u003cth\u003e作業量\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eCSE6040 Computing for Data Anlysis\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003eISYE6501 Introduction to Analytics Modeling\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003eCS6300 Software Development Process\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS6250 Computer Networks\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003eCS7646 Machine Learning for Trading\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6035 Introduction to Information Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003eCS6200 Introduction to Operating Systems\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e20時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003eCS6262 Network Security\u003c/td\u003e\n          \u003ctd\u003e普通\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS6515 Introduction to Graduate Algorithms\u003c/td\u003e\n          \u003ctd\u003e難しい\u003c/td\u003e\n          \u003ctd\u003e15時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003eCS9903-O13 Quantum Computing\u003c/td\u003e\n          \u003ctd\u003e易しい\u003c/td\u003e\n          \u003ctd\u003e10時間/週\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e受講したコースについて少し紹介しようと思います。2023年現在、OMSCSでは61コース提供されており\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e、定期的に追加・更新されます。また、OMSCSにはOMSCentral\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*3\u003c/a\u003eという非公式のレビューサイトがあるので、そちらも参考にしてみてください。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSを振り返って"},{"content":"ジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\nOMSCSとは Online Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\nこのプログラムの特徴としては以下が挙げられます*1。\n全てオンラインで完結すること 学費が安いこと オンキャンパスと同等の学位であること 近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています*2。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\n実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\n学期 米ドル 日本円 Fall 2020 $1951 21万円 Spring 2021 $455 5万円 Summer 2021 $841 9万円 Fall 2021 $1381 16万円 Spring 2022 $1341 17万円 Summer 2022 $841 11万円 Fall 2022 $1187 17万円 合計 $8037 96万円 最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\n出願方法 まずは出願の基準について見ていきたいと思います。OMSCSの公式サイトに記載されている基準は以下になります*3。\n学士号を有していること 関連分野(数学、電子工学など)の専攻であること GPAが3.0/4.0以上であること しかし、これは厳密な基準ではないので、全く違う分野の専攻であったり、GPAが3.0以下でも大丈夫なようです。音楽の専攻であったり、GPAが2.8でも合格したという記事を見かけたことがあります。\nまた、出願のスケジュールですが、現在は年間を通じていつでも応募できるようになっているようです。しかし、始められるのは秋学期もしくは春学期に限定されており、始める学期に応じて応募の締め切り期限が設けられています*4。\n秋学期(8月下旬)に開始したい場合、3/15までに出願 春学期(1月上旬)に開始したい場合、8/15までに出願 そして、出願に必要なものは以下になります*4。\n履歴書 成績表 3通の推薦書 TOEFL/IELTSのスコア Statement of Purpose 履歴書 履歴書は英語になります。英語の履歴書を書いたことがないと、一から作成するのは手間になると思いますが、LinkedInで書くような内容を記載しておけば大丈夫だと思います。英語の履歴書のフォーマットは特に決まっていないので、自分の好きなようにフォーマットを決めていただいて構いません。\n成績表 GPAは基本的に3.0以上が基準となりますが、2.8くらいで合格されている方もいるみたいです。成績表は在籍した全ての教育機関(高校以降に在籍した教育機関で、学位を授与されなかった場合も含む)からの成績表が必要となります。大学から直接送付してもらう必要はなく、大学のウェブサイトなどからダウンロードできる非公式なもので大丈夫です*4。合格した後に公式の成績表を大学からジョージア工科大学に送付してもらう必要があります。\n私は途中で違う大学に編入しているので、2つの大学のウェブサイトからそれぞれ成績表をダウンロードして提出しました。ちなみに1つ目の大学では学位は授与されていません。\n3通の推薦書 アカデミックな領域の方に書いてもらう推薦書が望ましいようです。また、同僚やクラスメートではなく、教師や上司などの推薦書の方が好ましいようです*4。\n大学でお世話になった物理の教授2人と学部時代のCSクラスでお世話になった博士課程に在籍している方に書いていただきました。\nTOEFL/IELTSのスコア なぜかページによって基準となるスコアに違いがありますが*5、おおよそ基準となるスコアは以下になります。\nTOEFL iBT: 90 (each section must score 19 or higher) IELTS: 7 (minimum band score for Reading, Listening, and Speaking is 6.5; minimum band score for Writing is 5.5) 出願時に提出したIELTSのスコアは7.5(Listening: 8.5, Reading:7.5 Writing: 6.5, Speaking: 6.5)でした。IELTSだと実際に人と話してスピーキングを試験するので、個人的にはTOEFLよりもIELTSのほうがおすすめです。\nStatement of Purpose 願書の最後に以下のような記入欄が出てきます。\nキャリアのゴール Briefly describe your eventual career objective. Your space is limited to 150 characters (e.g., University Professor, Industry Researcher, etc.).\n経歴紹介 Please describe your background (academic and extracurricular) and experience, including research, teaching, industry, and other relevant information. Your space is limited to 2000 characters.\nなぜこのプログラムに入りたいのか Please give a Statement of Purpose detailing your academic and research goals as well as career plans. Include your reasons for choosing the College of Computing as opposed to other programs and/or other universities. Your space is limited to 4000 characters.\n頑張って英語で書いて、英語ネイティブの友達に添削してもらいました。\nちなみに合否は締切期限の2週間後くらいに発表されます。私の場合、OMSAで秋学期開始の時は4月10日で、OMSCSで春学期開始の時は8月26日でした。\n合格した後は、公式の成績表と卒業証明書を大学からジョージア工科大学に送付してもらう必要があります。\nまとめ ジョージア工科大学より提供されているOMSCSについてご紹介しました。オンライン修士号のプログラムは増えつつありますが、OMSCSが1番最初に始めたということもあり、他のプログラムよりも人気だと思います。また、学費も他のプログラムに比べて低く抑えられていたり、提供されているコースもかなり多いので、個人的には1番おすすめです。もしOMSCSに興味があって、出願を考えている人の参考になれば幸いです。\n参考 *1 Dr.David Joyner\u0026rsquo;s Presentation *2 User Clip: Obama OMSCS *3 Admission Criteria *4 Application Deadlines, Process and Requirements *5 TOEFL/IELTSのスコアに関して記載されているページ:\nComputer Science(Online) English Proficiency ","permalink":"http://localhost:1313/posts/omscs/","summary":"\u003cp\u003eジョージア工科大学 コンピューターサイエンス修士課程(通称OMSCS)の概要とその出願方法について紹介します。\u003c/p\u003e\n\u003ch2 id=\"omscsとは\"\u003eOMSCSとは\u003c/h2\u003e\n\u003cp\u003eOnline Master of Science in Computer Science (OMSCS)はアメリカの州立大学であるジョージア工科大学が提供しているプログラムになります。\u003c/p\u003e\n\u003cp\u003eこのプログラムの特徴としては以下が挙げられます\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*1\u003c/a\u003e。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e全てオンラインで完結すること\u003c/li\u003e\n\u003cli\u003e学費が安いこと\u003c/li\u003e\n\u003cli\u003eオンキャンパスと同等の学位であること\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e近年、MOOCなどオンラインで取得できる学位プログラムは増えつつありますが、OMSCSは2014に開始され、オンラインの学位プログラムとしては先駆け的な存在です。また、OMSCSは学費が安いことを売りにしており、オバマ元大統領も言及しています\u003ca href=\"#%E5%8F%82%E8%80%83\"\u003e*2\u003c/a\u003e。そして、OMSCSはオンラインの学位とオンキャンパスの学位を区別せず、同等の学位として扱います。卒業証書には\u0026quot;Master of Science in Computer Science\u0026quot;と記載されます。\u003c/p\u003e\n\u003cp\u003e実際に私が支払った金額を参考までに載せておきます。(Spring 2021は諸々の事情により、学期の途中から休学することにしました。)\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e学期\u003c/th\u003e\n          \u003cth\u003e米ドル\u003c/th\u003e\n          \u003cth\u003e日本円\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2020\u003c/td\u003e\n          \u003ctd\u003e$1951\u003c/td\u003e\n          \u003ctd\u003e21万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2021\u003c/td\u003e\n          \u003ctd\u003e$455\u003c/td\u003e\n          \u003ctd\u003e5万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2021\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e9万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2021\u003c/td\u003e\n          \u003ctd\u003e$1381\u003c/td\u003e\n          \u003ctd\u003e16万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSpring 2022\u003c/td\u003e\n          \u003ctd\u003e$1341\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSummer 2022\u003c/td\u003e\n          \u003ctd\u003e$841\u003c/td\u003e\n          \u003ctd\u003e11万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFall 2022\u003c/td\u003e\n          \u003ctd\u003e$1187\u003c/td\u003e\n          \u003ctd\u003e17万円\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003e合計\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e$8037\u003c/td\u003e\n          \u003ctd\u003e96万円\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e最近ではOMSCS以外にもOnline Master of Science in Analytics (OMSA)やOnline Master of Science in Cybersecurity (OMS Cybersecurity)などのプログラムが提供されています。\u003c/p\u003e","title":"ジョージア工科大学 OMSCSへの出願方法"},{"content":"I am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\nExperience Period Position 2024/01 - Present Infrastructure Engineer @ Wantedly, Inc. 2021/01 - 2023/12 Database Engineer @ NTT DATA, Inc. Education Period Degree 2020/08 - 2022/12 MSc in Computer Science @ Georgia Institute of Technology 2016/09 - 2020/06 BSc in Physics @ Queen\u0026rsquo;s University Talks Speaker Deck Contributions postgresql jpug-docs prometheus ","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eI am a Cloud Infrastructure Engineer / DevOps Engineer / Site Reliability Engineer with experience in Kubernetes, PostgreSQL, AWS, Terraform, and Go.\u003c/p\u003e\n\u003ch2 id=\"experience\"\u003eExperience\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003ePosition\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2024/01 - Present\u003c/td\u003e\n          \u003ctd\u003eInfrastructure Engineer @ Wantedly, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2021/01 - 2023/12\u003c/td\u003e\n          \u003ctd\u003eDatabase Engineer @ NTT DATA, Inc.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003ePeriod\u003c/th\u003e\n          \u003cth\u003eDegree\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2020/08 - 2022/12\u003c/td\u003e\n          \u003ctd\u003eMSc in Computer Science @ Georgia Institute of Technology\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e2016/09 - 2020/06\u003c/td\u003e\n          \u003ctd\u003eBSc in Physics @ Queen\u0026rsquo;s University\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"talks\"\u003eTalks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://speakerdeck.com/kkato1\"\u003eSpeaker Deck\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"contributions\"\u003eContributions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://git.postgresql.org/gitweb/?p=postgresql.git\u0026amp;a=search\u0026amp;h=HEAD\u0026amp;st=commit\u0026amp;s=Ken+Kato\"\u003epostgresql\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/pgsql-jp/jpug-doc/pulls?q=is%3Apr+author%3Akkato+\"\u003ejpug-docs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/prometheus/docs/pulls?q=is%3Apr+author%3Akkato+\"\u003eprometheus\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Ken Kato"}]